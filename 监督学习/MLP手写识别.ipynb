{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.0001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from os import listdir\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "# 加载训练数据\n",
    "def img2vector(fileName):    \n",
    "    retMat = np.zeros([1024],int) #定义返回的矩阵，大小为1*1024\n",
    "    fr = open(fileName)           #打开包含32*32大小的数字文件 \n",
    "    lines = fr.readlines()        #读取文件的所有行\n",
    "    for i in range(32):           #遍历文件所有行\n",
    "        for j in range(32):       #并将01数字存放在retMat中     \n",
    "            retMat[i*32+j] = lines[i][j]    \n",
    "    return retMat\n",
    "\n",
    "def readDataSet(path):    \n",
    "    fileList = listdir(path)    #获取文件夹下的所有文件 \n",
    "    numFiles = len(fileList)    #统计需要读取的文件的数目\n",
    "    dataSet = np.zeros([numFiles,1024],int) #用于存放所有的数字文件\n",
    "    hwLabels = np.zeros([numFiles,10])      #用于存放对应的one-hot标签\n",
    "    for i in range(numFiles):   #遍历所有的文件\n",
    "        filePath = fileList[i]  #获取文件名称/路径      \n",
    "        digit = int(filePath.split('_')[0])  #通过文件名获取标签      \n",
    "        hwLabels[i][digit] = 1.0        #将对应的one-hot标签置1\n",
    "        dataSet[i] = img2vector(path +'/'+filePath) #读取文件内容   \n",
    "    return dataSet,hwLabels\n",
    "\n",
    "train_dataSet, train_hwLabels = readDataSet('./data/handwrite/digits/trainingDigits')\n",
    "\n",
    "# 训练神经网络\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,),   # 设置100个神经元隐藏层\n",
    "                    activation='logistic', solver='adam',\n",
    "                    learning_rate_init = 0.0001, max_iter=2000)  #  使用logistic激活函数和adam优化方法，并令初始学习率为0.0001\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " fit函数能够根据训练集及对应标签集自动设置多层感知机的输入与输\n",
    "出层的神经元个数\n",
    " 例如train_dataSet为n*1024的矩阵，train_hwLabels为n*10的矩阵，\n",
    "则fit函数将MLP的输入层神经元个数设为1024，输出层神经元个数为\n",
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.0001, max_iter=2000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_dataSet,train_hwLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num: 946  Wrong num: 38   WrongRate: 0.040169133192389\n"
     ]
    }
   ],
   "source": [
    "# 测试集评价\n",
    "dataSet,hwLabels = readDataSet('./data/handwrite/digits/testDigits')\n",
    "res = clf.predict(dataSet)   #对测试集进行预测\n",
    "error_num = 0                #统计预测错误的数目\n",
    "num = len(dataSet)           #测试集的数目\n",
    "for i in range(num):         #遍历预测结果\n",
    "    #比较长度为10的数组，返回包含01的数组，0为不同，1为相同\n",
    "    #若预测结果与真实结果相同，则10个数字全为1，否则不全为1\n",
    "    if np.sum(res[i] == hwLabels[i]) < 10: \n",
    "        error_num += 1\n",
    "        \n",
    "print(\"Total num:\",num,\" Wrong num:\", \\\n",
    "      error_num,\"  WrongRate:\",error_num / float(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "过小的迭代次数可能使得MLP早停，造成较低的正确率。\n",
    "当最大迭代次数>1000时，正确率基本保持不变，这说明MLP在第1000迭代时已收敛，\n",
    "剩余的迭代次数不再进行。\n",
    "一般设置较大的最大迭代次数来保证多层感知机能够收敛，达到较高的正确率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
